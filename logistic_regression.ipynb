{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import metrics_summary as ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data/X_train.csv\")\n",
    "X_test = pd.read_csv(\"data/X_test.csv\")\n",
    "y_train = pd.read_csv(\"data/y_train.csv\").values.ravel()\n",
    "y_test = pd.read_csv(\"data/y_test.csv\").values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(170)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(236866, 53) (236866,)\n"
     ]
    }
   ],
   "source": [
    "# implement SMOTE to oversample the minority class\n",
    "from imblearn.over_sampling import SMOTE\n",
    "os = SMOTE()\n",
    "X_os, y_os = os.fit_resample(X_train, y_train)\n",
    "print(X_os.shape, y_os.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the oversample data (keeping code for now in case we need it later)\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# os_X_train, os_X_test, os_y_train, os_y_test = train_test_split(os_X, os_y, test_size=0.30, random_state=0)\n",
    "# print(os_X_train.shape, os_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.060688\n",
      "         Iterations 10\n",
      "                         Results: Logit\n",
      "=================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.820     \n",
      "Dependent Variable: y                AIC:              16174.3946\n",
      "Date:               2022-05-16 22:42 BIC:              16693.4489\n",
      "No. Observations:   132386           Log-Likelihood:   -8034.2   \n",
      "Df Model:           52               LL-Null:          -44585.   \n",
      "Df Residuals:       132333           LLR p-value:      0.0000    \n",
      "Converged:          1.0000           Scale:            1.0000    \n",
      "No. Iterations:     10.0000                                      \n",
      "------------------------------------------------------------------\n",
      "               Coef.   Std.Err.     z     P>|z|    [0.025   0.975]\n",
      "------------------------------------------------------------------\n",
      "AB1            0.2536    0.0254   9.9915  0.0000   0.2038   0.3033\n",
      "AB118          0.1142    0.0524   2.1808  0.0292   0.0116   0.2168\n",
      "AB29V2        -0.2691    0.0587  -4.5853  0.0000  -0.3841  -0.1541\n",
      "AB30           0.0415    0.0320   1.2974  0.1945  -0.0212   0.1043\n",
      "AB34           0.4559    0.1100   4.1454  0.0000   0.2404   0.6715\n",
      "AB40           0.0711    0.1026   0.6928  0.4884  -0.1300   0.2721\n",
      "AB43          -0.0984    0.1099  -0.8951  0.3707  -0.3138   0.1170\n",
      "AB63           1.5718    0.0215  73.0123  0.0000   1.5296   1.6140\n",
      "AB99          -0.0966    0.0592  -1.6308  0.1029  -0.2126   0.0195\n",
      "AE2            0.0018    0.0390   0.0453  0.9638  -0.0747   0.0782\n",
      "AE7           -0.0083    0.0377  -0.2217  0.8245  -0.0821   0.0655\n",
      "AJ80           0.4084    0.0224  18.2693  0.0000   0.3646   0.4522\n",
      "AK1           -0.0605    0.0473  -1.2806  0.2003  -0.1532   0.0321\n",
      "AL18AV2        0.0389    0.0255   1.5256  0.1271  -0.0111   0.0888\n",
      "AK4           -0.0736    0.0342  -2.1502  0.0315  -0.1406  -0.0065\n",
      "ACMDNUM       -0.0067    0.0091  -0.7388  0.4600  -0.0245   0.0111\n",
      "AE_FRUIT      -0.0048    0.1680  -0.0283  0.9774  -0.3341   0.3246\n",
      "AE_VEGI        0.0339    0.1622   0.2087  0.8347  -0.2840   0.3517\n",
      "ASTCUR         0.1348    0.1026   1.3134  0.1890  -0.0663   0.3358\n",
      "MARIT_45       0.0206    0.0148   1.3910  0.1642  -0.0084   0.0496\n",
      "DSTRSYR       -0.0013    0.0120  -0.1045  0.9167  -0.0247   0.0222\n",
      "INST_12        0.0367    0.0177   2.0740  0.0381   0.0020   0.0714\n",
      "RBMI           0.1478    0.0672   2.1996  0.0278   0.0161   0.2794\n",
      "OVRWT         -0.1607    0.0948  -1.6943  0.0902  -0.3465   0.0252\n",
      "AK10_P        -0.0000    0.0000  -1.6744  0.0941  -0.0000   0.0000\n",
      "AK22_P         0.0000    0.0000   0.9446  0.3449  -0.0000   0.0000\n",
      "HGHTI_P       -0.0134    0.0070  -1.9067  0.0566  -0.0272   0.0004\n",
      "WGHTP_P        0.0034    0.0014   2.3347  0.0196   0.0005   0.0062\n",
      "BMI_P          0.0085    0.0080   1.0613  0.2885  -0.0072   0.0241\n",
      "INS64_P       -0.0790    0.0284  -2.7838  0.0054  -0.1347  -0.0234\n",
      "INSTYPE        0.0847    0.0222   3.8207  0.0001   0.0412   0.1281\n",
      "POVGWD_P1      0.0322    0.0115   2.8084  0.0050   0.0097   0.0547\n",
      "DSTRS_P1      -0.0120    0.0204  -0.5865  0.5575  -0.0519   0.0280\n",
      "SRAGE_P1       0.0502    0.0030  16.6547  0.0000   0.0443   0.0561\n",
      "AHEDC_P1       0.0677    0.0111   6.0817  0.0000   0.0459   0.0896\n",
      "WRKST_P1      -0.0195    0.0420  -0.4634  0.6430  -0.1018   0.0629\n",
      "AK2_P1         0.0002    0.0013   0.1200  0.9045  -0.0024   0.0027\n",
      "AB27_P1        0.0004    0.0001   2.8309  0.0046   0.0001   0.0006\n",
      "AB28_P1        0.6005    0.0193  31.1095  0.0000   0.5626   0.6383\n",
      "YEAR          -0.0030    0.0003  -9.3134  0.0000  -0.0036  -0.0024\n",
      "AB26_P1       -0.0036    0.0005  -7.8414  0.0000  -0.0044  -0.0027\n",
      "DISTRESS      -0.0039    0.0164  -0.2398  0.8105  -0.0362   0.0283\n",
      "DIABCK_P1      0.0461    0.0057   8.0342  0.0000   0.0349   0.0574\n",
      "AC47           0.0027    0.0029   0.9235  0.3557  -0.0030   0.0084\n",
      "PREDIAB       -0.7040    0.0833  -8.4522  0.0000  -0.8673  -0.5408\n",
      "POVLL2_P1V2   -0.0071    0.0136  -0.5192  0.6036  -0.0337   0.0196\n",
      "AJ168         -0.0225    0.0245  -0.9176  0.3588  -0.0705   0.0256\n",
      "AK22_P1        0.0043    0.0043   1.0025  0.3161  -0.0041   0.0127\n",
      "AH5           -0.0035    0.0026  -1.3402  0.1802  -0.0085   0.0016\n",
      "AH132          0.0549    0.0178   3.0890  0.0020   0.0201   0.0897\n",
      "AH136         -0.0001    0.0002  -0.4975  0.6188  -0.0006   0.0003\n",
      "TCURPLAN      -0.0551    0.0178  -3.0948  0.0020  -0.0900  -0.0202\n",
      "AB27_P         0.4343    0.0193  22.5144  0.0000   0.3965   0.4721\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check p-values of features\n",
    "import statsmodels.api as sm\n",
    "logit_model = sm.Logit(y_train, X_train)\n",
    "result = logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature with p-values less than 0.05 are the significant ones. Consider getting rid of insignificant features and then fit it into the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brian\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49798   897]\n",
      " [ 3389  2653]]\n",
      "=================================================\n",
      "Kappa Score: 0.5149340214729062\n",
      "Accuracy Score: 0.9244584662565875\n",
      "Precision: 0.7473239436619719\n",
      "Recall: 0.4390930155577623\n",
      "F1 Score: 0.5531693077564637\n",
      "AUC Score: 0.7106994814449232\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brian\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Brian\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Brian\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Brian\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================\n",
      "Average Accuracy Score: 0.9225144890507107\n",
      "Average Precision Score: 0.7509451078835438\n",
      "Average Recall Score: 0.40306420149764544\n",
      "Average F1 Score: 0.9225144890507107\n",
      "Average AUC Score: 0.928102946487612\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brian\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.928102946487612"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "ms.metrics_summary(y_test, y_pred)\n",
    "ms.crossval_summary(logreg, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brian\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43991  6704]\n",
      " [ 1058  4984]]\n",
      "=================================================\n",
      "Kappa Score: 0.49070440694665984\n",
      "Accuracy Score: 0.8631933306308053\n",
      "Precision: 0.4264202600958248\n",
      "Recall: 0.8248924197285668\n",
      "F1 Score: 0.5622109419063734\n",
      "AUC Score: 0.8463252906414802\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brian\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Brian\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Brian\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Brian\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================\n",
      "Average Accuracy Score: 0.8716329809661998\n",
      "Average Precision Score: 0.44352644935888746\n",
      "Average Recall Score: 0.8382397850746575\n",
      "Average F1 Score: 0.8716329809661998\n",
      "Average AUC Score: 0.9361968100628928\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brian\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9361968100628928"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cs = LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
    "logreg_cs.fit(X_train, y_train)\n",
    "y_pred = logreg_cs.predict(X_test)\n",
    "ms.metrics_summary(y_test, y_pred)\n",
    "ms.crossval_summary(logreg_cs, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using oversampled data from SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brian\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43852  6843]\n",
      " [ 1001  5041]]\n",
      "=================================================\n",
      "Kappa Score: 0.490481059785041\n",
      "Accuracy Score: 0.861748065636181\n",
      "Precision: 0.42418377650622685\n",
      "Recall: 0.8343263819927177\n",
      "F1 Score: 0.5624232957715052\n",
      "AUC Score: 0.8496713278934889\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brian\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Brian\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Brian\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Brian\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================\n",
      "Average Accuracy Score: 0.8678112839395359\n",
      "Average Precision Score: 0.868505642788174\n",
      "Average Recall Score: 0.8668696514441819\n",
      "Average F1 Score: 0.8678112839395359\n",
      "Average AUC Score: 0.9407807495625093\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brian\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9407807495625093"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_os = LogisticRegression(max_iter=1000)\n",
    "logreg_os.fit(X_os, y_os)\n",
    "y_pred = logreg_os.predict(X_test)\n",
    "ms.metrics_summary(y_test, y_pred)\n",
    "ms.crossval_summary(logreg_os, X_os, y_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use variance inflation factor to identify any significant multi-collinearity\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# X_constant = sm.add_constant(X_train, prepend=False)\n",
    "# vif = pd.DataFrame()\n",
    "# vif[\"Features\"] = X_constant.columns\n",
    "# vif[\"VIF\"] = [variance_inflation_factor(X_constant.values, i) for i in range(X_constant.shape[1])]\n",
    "# vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set(font_scale=1.25)\n",
    "# # chis_train = pd.concat([X_train, y_train], axis=1)\n",
    "# # chis_train = chis_train.rename(columns = {'T2D': 'Type 2 Diabetes', 'AB24': 'Taking Insulin', 'AB23_P1': 'Age Told To Have Diabetes', 'AB112': 'Diabetes Care Plan', \n",
    "# # 'AB25': 'Diabetic Pills', 'AB63': 'Eye Exam Dilated Pupils', 'AB114_P1': 'Confidence to Control Diabetes', 'AB28_P1': 'Doctor Checked Feet for Sores', 'AB109': 'Visited ER', \n",
    "# # 'AB113': 'Copy of Diabetes Care Plan', 'AB111': \"Hospital Overnight for Diabetes\"})\n",
    "\n",
    "# corrMatrix = X_train.corr()\n",
    "# plt.subplots(figsize=(24, 18))\n",
    "# # g = sns.heatmap(corrMatrix, annot=True, cmap=\"Accent\", vmin=-1, vmax=1)\n",
    "# g = sns.heatmap(corrMatrix, annot=True, cmap=\"Accent\")\n",
    "# plt.title('Correlation Heatmap', size = 25)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_constant' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21068/3700573985.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Setup logistic regression model (using GLM method so that we can retrieve residuals)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlogit_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGLM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_constant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfamilies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBinomial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mlogit_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogit_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_constant' is not defined"
     ]
    }
   ],
   "source": [
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "from statsmodels.genmod import families\n",
    "\n",
    "# Setup logistic regression model (using GLM method so that we can retrieve residuals)\n",
    "logit_model = GLM(y_train, X_constant, family=families.Binomial())\n",
    "logit_results = logit_model.fit()\n",
    "print(logit_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "# Generate residual series plot\n",
    "fig = plt.figure(figsize=(15,9))\n",
    "ax = fig.add_subplot(111, title=\"Residual Series Plot\",\n",
    "                    xlabel=\"Index Number\", ylabel=\"Deviance Residuals\")\n",
    "\n",
    "# ax.plot(X.index.tolist(), stats.zscore(logit_results.resid_pearson))\n",
    "ax.plot(X_constant.index.tolist(), scipy.stats.zscore(logit_results.resid_deviance))\n",
    "plt.axhline(y=0, ls=\"--\", color='red');"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae5651488652e961febbac79b6ac121d2261f82ccebdbef63236855c9fe5b051"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
