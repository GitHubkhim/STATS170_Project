{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import metrics_summary as ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data/X_train.csv\")\n",
    "X_test = pd.read_csv(\"data/X_test.csv\")\n",
    "y_train = pd.read_csv(\"data/y_train.csv\").values.ravel()\n",
    "y_test = pd.read_csv(\"data/y_test.csv\").values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(170)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.250358\n",
      "         Iterations 9\n",
      "                             Results: Logit\n",
      "========================================================================\n",
      "Model:                 Logit              Pseudo R-squared:   0.258     \n",
      "Dependent Variable:    y                  AIC:                66841.8354\n",
      "Date:                  2022-05-29 03:23   BIC:                69554.6286\n",
      "No. Observations:      132386             Log-Likelihood:     -33144.   \n",
      "Df Model:              276                LL-Null:            -44677.   \n",
      "Df Residuals:          132109             LLR p-value:        0.0000    \n",
      "Converged:             1.0000             Scale:              1.0000    \n",
      "No. Iterations:        9.0000                                           \n",
      "------------------------------------------------------------------------\n",
      "             Coef.    Std.Err.     z     P>|z|     [0.025       0.975]  \n",
      "------------------------------------------------------------------------\n",
      "AB1          0.4991      0.0124  40.2394 0.0000       0.4747      0.5234\n",
      "AB115        0.1556      0.0305   5.0978 0.0000       0.0958      0.2154\n",
      "AB118        0.0342      0.0391   0.8737 0.3823      -0.0425      0.1109\n",
      "AB17        -0.1501      0.5904  -0.2542 0.7993      -1.3072      1.0070\n",
      "AB18         0.0324      0.0242   1.3369 0.1812      -0.0151      0.0799\n",
      "AB29V2      -0.4933      0.0334 -14.7787 0.0000      -0.5587     -0.4279\n",
      "AB30         0.0267      0.0191   1.3982 0.1621      -0.0107      0.0640\n",
      "AB34        -0.0939      0.0465  -2.0206 0.0433      -0.1850     -0.0028\n",
      "AB40        -0.0906      0.1576  -0.5747 0.5655      -0.3994      0.2183\n",
      "AB41         0.0891      0.0597   1.4925 0.1356      -0.0279      0.2061\n",
      "AB43        -0.0552      0.0863  -0.6394 0.5225      -0.2242      0.1139\n",
      "AB52        -0.0901      0.0344  -2.6212 0.0088      -0.1575     -0.0227\n",
      "AB98        -0.0028      0.0290  -0.0957 0.9238      -0.0596      0.0541\n",
      "AB99         0.0172      0.0229   0.7503 0.4531      -0.0278      0.0622\n",
      "AC11        -0.1464      0.0192  -7.6362 0.0000      -0.1840     -0.1089\n",
      "AC32         0.3690      0.0330  11.1909 0.0000       0.3044      0.4336\n",
      "AC44         0.0068      0.0109   0.6271 0.5306      -0.0145      0.0282\n",
      "AD37W       -0.0754      0.0313  -2.4091 0.0160      -0.1367     -0.0141\n",
      "AD39W        0.0006      0.0005   1.0554 0.2912      -0.0005      0.0016\n",
      "AD40W        0.0177      0.0269   0.6558 0.5119      -0.0351      0.0704\n",
      "AD41W        0.0080      0.0035   2.2715 0.0231       0.0011      0.0149\n",
      "AD42W       -0.0004      0.0005  -0.7715 0.4404      -0.0013      0.0006\n",
      "AD50        -0.1002      0.0307  -3.2665 0.0011      -0.1603     -0.0401\n",
      "AD51         0.0527      0.0412   1.2792 0.2008      -0.0280      0.1334\n",
      "AD52         0.1297      0.0535   2.4240 0.0154       0.0248      0.2345\n",
      "AD53         0.0834      0.0465   1.7919 0.0731      -0.0078      0.1745\n",
      "AD54         0.0024      0.0261   0.0922 0.9266      -0.0487      0.0535\n",
      "AD57         0.0650      0.0469   1.3871 0.1654      -0.0269      0.1569\n",
      "AE15        -1.1317      0.4099  -2.7611 0.0058      -1.9350     -0.3283\n",
      "AE15A       -0.1992      0.0790  -2.5234 0.0116      -0.3540     -0.0445\n",
      "AE2          0.0079      0.0172   0.4615 0.6445      -0.0258      0.0416\n",
      "AE3          0.0480      0.0157   3.0640 0.0022       0.0173      0.0788\n",
      "AE30        -0.2959      0.0296 -10.0069 0.0000      -0.3538     -0.2379\n",
      "AE7          0.0314      0.0170   1.8455 0.0650      -0.0019      0.0647\n",
      "AF62        -0.1494      0.1924  -0.7764 0.4375      -0.5265      0.2277\n",
      "AF63         0.0146      0.0268   0.5436 0.5868      -0.0379      0.0670\n",
      "AF64         0.0040      0.0311   0.1298 0.8967      -0.0569      0.0650\n",
      "AF65         0.0072      0.0262   0.2743 0.7839      -0.0442      0.0586\n",
      "AF66        -0.0911      0.0297  -3.0683 0.0022      -0.1493     -0.0329\n",
      "AF67         0.0441      0.0262   1.6829 0.0924      -0.0073      0.0954\n",
      "AF68        -0.0160      0.0284  -0.5628 0.5736      -0.0715      0.0396\n",
      "AF69B        0.0199      0.0144   1.3864 0.1656      -0.0082      0.0481\n",
      "AF70B       -0.3770         nan      nan    nan          nan         nan\n",
      "AF71B        0.6505 313407.1453   0.0000 1.0000 -614266.0667 614267.3678\n",
      "AF72B       -0.2568         nan      nan    nan          nan         nan\n",
      "AG10        -0.0288      0.0138  -2.0911 0.0365      -0.0557     -0.0018\n",
      "AG11        -0.0124      0.0576  -0.2150 0.8297      -0.1254      0.1006\n",
      "AG22         0.1491      0.1065   1.4004 0.1614      -0.0596      0.3578\n",
      "AG8          0.0283      0.0404   0.7006 0.4836      -0.0508      0.1074\n",
      "AH1          0.0187      0.0134   1.3978 0.1622      -0.0075      0.0450\n",
      "AH12V2      -0.1915      0.0289  -6.6268 0.0000      -0.2481     -0.1348\n",
      "AH14        -0.1131      0.0221  -5.1237 0.0000      -0.1563     -0.0698\n",
      "AH16        -0.5729      0.1531  -3.7422 0.0002      -0.8729     -0.2728\n",
      "AH22         0.1220      0.2353   0.5186 0.6041      -0.3392      0.5833\n",
      "AH37         0.0391      0.0374   1.0466 0.2953      -0.0341      0.1123\n",
      "AH44         0.0088      0.0768   0.1151 0.9084      -0.1417      0.1594\n",
      "AH44A       -0.0645      0.0175  -3.6917 0.0002      -0.0988     -0.0303\n",
      "AH6         -0.4153      0.0540  -7.6845 0.0000      -0.5212     -0.3094\n",
      "AI22C        0.0186      0.0156   1.1922 0.2332      -0.0120      0.0492\n",
      "AI25        -0.1251      0.0365  -3.4295 0.0006      -0.1966     -0.0536\n",
      "AI37A        0.0325      0.0212   1.5317 0.1256      -0.0091      0.0742\n",
      "AI4         -0.0267      0.0173  -1.5466 0.1220      -0.0605      0.0071\n",
      "AJ1         -0.0221      0.0157  -1.4068 0.1595      -0.0529      0.0087\n",
      "AJ10V2      -0.0267      0.0139  -1.9144 0.0556      -0.0540      0.0006\n",
      "AJ102        0.1168      0.0422   2.7660 0.0057       0.0340      0.1995\n",
      "AJ103        0.0085      0.0115   0.7405 0.4590      -0.0141      0.0312\n",
      "AJ105       -0.1039      0.0365  -2.8483 0.0044      -0.1753     -0.0324\n",
      "AJ106       -0.0523      0.0288  -1.8184 0.0690      -0.1088      0.0041\n",
      "AJ107       -0.0442      0.0197  -2.2490 0.0245      -0.0828     -0.0057\n",
      "AJ108        0.1276      0.0719   1.7741 0.0761      -0.0134      0.2685\n",
      "AJ109        0.0398      0.0245   1.6225 0.1047      -0.0083      0.0879\n",
      "AJ110       -0.0106      0.0185  -0.5736 0.5662      -0.0468      0.0256\n",
      "AJ111       -0.0258      0.0227  -1.1364 0.2558      -0.0702      0.0187\n",
      "AJ112       -0.0492      0.0246  -1.9992 0.0456      -0.0975     -0.0010\n",
      "AJ113        0.0638      0.0245   2.6040 0.0092       0.0158      0.1118\n",
      "AJ19        -0.1650      0.0604  -2.7308 0.0063      -0.2834     -0.0466\n",
      "AJ20        -0.0287      0.0913  -0.3147 0.7530      -0.2076      0.1502\n",
      "AJ29         0.0886      0.0236   3.7529 0.0002       0.0423      0.1348\n",
      "AJ30        -0.0005      0.0269  -0.0190 0.9848      -0.0532      0.0522\n",
      "AJ31         0.0268      0.0232   1.1569 0.2473      -0.0186      0.0722\n",
      "AJ32         0.0300      0.0282   1.0618 0.2883      -0.0253      0.0853\n",
      "AJ33         0.0493      0.0226   2.1853 0.0289       0.0051      0.0935\n",
      "AJ34         0.0137      0.0264   0.5195 0.6034      -0.0380      0.0654\n",
      "AJ77        -0.2427      0.0590  -4.1118 0.0000      -0.3584     -0.1270\n",
      "AJ78         0.0028      0.0555   0.0507 0.9596      -0.1060      0.1117\n",
      "AJ79         0.0150      0.0144   1.0450 0.2960      -0.0131      0.0431\n",
      "AJ8V3       -0.0324      0.0168  -1.9256 0.0542      -0.0654      0.0006\n",
      "AK1          0.0109      0.0229   0.4739 0.6356      -0.0340      0.0557\n",
      "AK23         0.0058      0.0113   0.5138 0.6074      -0.0164      0.0280\n",
      "AK25         0.0127      0.0092   1.3895 0.1647      -0.0052      0.0307\n",
      "AK28        -0.0212      0.0163  -1.3026 0.1927      -0.0532      0.0107\n",
      "AK8          0.0028      0.0067   0.4145 0.6785      -0.0104      0.0160\n",
      "AL18AV2      0.0432      0.0174   2.4895 0.0128       0.0092      0.0773\n",
      "AL2V2       -0.0733      0.0584  -1.2551 0.2094      -0.1877      0.0411\n",
      "AL22         0.0385      0.0173   2.2174 0.0266       0.0045      0.0725\n",
      "AL5V2       -0.0186      0.0471  -0.3942 0.6934      -0.1109      0.0738\n",
      "AL6V2        0.0740      0.0382   1.9366 0.0528      -0.0009      0.1489\n",
      "AM1         -0.0608      0.0332  -1.8303 0.0672      -0.1259      0.0043\n",
      "AM19         0.0049      0.0174   0.2797 0.7797      -0.0292      0.0389\n",
      "AM2         -0.0549      0.0318  -1.7223 0.0850      -0.1173      0.0076\n",
      "AM21        -0.0060      0.0185  -0.3220 0.7475      -0.0423      0.0303\n",
      "AM3          0.1115      0.0504   2.2149 0.0268       0.0128      0.2102\n",
      "AM34         0.0033      0.0069   0.4722 0.6368      -0.0102      0.0168\n",
      "AM35         0.0093      0.0116   0.7971 0.4254      -0.0135      0.0320\n",
      "AM36         0.0633      0.0266   2.3833 0.0172       0.0112      0.1154\n",
      "AM37        -0.0162      0.0172  -0.9415 0.3465      -0.0500      0.0175\n",
      "AM39        -0.0522      0.0380  -1.3723 0.1700      -0.1267      0.0223\n",
      "AM4         -0.0065      0.0566  -0.1143 0.9090      -0.1174      0.1044\n",
      "AM40         0.0259      0.0380   0.6815 0.4955      -0.0486      0.1005\n",
      "AM5          0.0143      0.0582   0.2452 0.8063      -0.0998      0.1283\n",
      "SRSEX       -0.1910      0.0448  -4.2628 0.0000      -0.2789     -0.1032\n",
      "SRTENR      -0.0083      0.0345  -0.2399 0.8104      -0.0758      0.0593\n",
      "SRH         -0.1998      0.0539  -3.7094 0.0002      -0.3054     -0.0942\n",
      "SRW          0.0342      0.0532   0.6427 0.5204      -0.0700      0.1384\n",
      "SRAA        -0.0737      0.0629  -1.1713 0.2415      -0.1969      0.0496\n",
      "MARIT       -0.0577      0.1732  -0.3334 0.7388      -0.3971      0.2816\n",
      "AK4         -0.0371      0.0190  -1.9559 0.0505      -0.0743      0.0001\n",
      "POVLL       -0.0111      0.0280  -0.3952 0.6927      -0.0660      0.0439\n",
      "UR_TRACT     0.0372      0.0373   0.9971 0.3187      -0.0359      0.1102\n",
      "UR_BG       -0.0599      0.0363  -1.6483 0.0993      -0.1311      0.0113\n",
      "UR_IHS       0.1237      0.0247   5.0159 0.0000       0.0753      0.1720\n",
      "UR_OMB      -0.0738      0.0534  -1.3814 0.1671      -0.1786      0.0309\n",
      "UR_RHP       0.0109      0.0426   0.2548 0.7989      -0.0726      0.0943\n",
      "INSMC       -0.2506      0.0918  -2.7282 0.0064      -0.4306     -0.0706\n",
      "INSMD       -0.0865      0.0594  -1.4566 0.1452      -0.2030      0.0299\n",
      "INSEM       -0.0026      0.0725  -0.0365 0.9709      -0.1446      0.1394\n",
      "INSPS       -0.0389      0.0359  -1.0855 0.2777      -0.1092      0.0314\n",
      "INS65        0.0066      0.0359   0.1846 0.8536      -0.0637      0.0769\n",
      "UNINSANY     0.0218      0.0351   0.6208 0.5347      -0.0470      0.0906\n",
      "INSMC_S     -0.0242      0.0841  -0.2873 0.7739      -0.1890      0.1406\n",
      "INSMD_S     -0.0461      0.0731  -0.6305 0.5284      -0.1894      0.0972\n",
      "INSEM_S     -0.2112      0.1108  -1.9072 0.0565      -0.4283      0.0058\n",
      "INSPR_S      0.0285      0.0769   0.3712 0.7105      -0.1222      0.1793\n",
      "INSOG_S      0.2079      0.1161   1.7904 0.0734      -0.0197      0.4355\n",
      "INSPS_S     -0.0722      0.0458  -1.5767 0.1149      -0.1619      0.0175\n",
      "INS_S        0.0473      0.1133   0.4178 0.6761      -0.1747      0.2694\n",
      "HMO         -0.0473      0.0265  -1.7836 0.0745      -0.0992      0.0047\n",
      "ACMDNUM      0.0574      0.0048  11.9199 0.0000       0.0480      0.0669\n",
      "AE_FRIES    -0.2099      0.0654  -3.2110 0.0013      -0.3381     -0.0818\n",
      "AE_FRUIT    -0.0300      0.0743  -0.4042 0.6860      -0.1757      0.1156\n",
      "AE_SODA      0.6690      0.0838   7.9794 0.0000       0.5047      0.8334\n",
      "AE_VEGI     -0.1361      0.0722  -1.8861 0.0593      -0.2775      0.0053\n",
      "AH33NEW     -0.4257      0.2369  -1.7964 0.0724      -0.8901      0.0387\n",
      "AH34NEW     -0.0769      0.0421  -1.8265 0.0678      -0.1595      0.0056\n",
      "AH35NEW      0.0435      0.0397   1.0962 0.2730      -0.0343      0.1214\n",
      "AI22A_P     -0.0002      0.0041  -0.0597 0.9524      -0.0083      0.0078\n",
      "AKWKLNG      0.0019      0.0067   0.2853 0.7754      -0.0112      0.0150\n",
      "ASTCUR       0.1958      0.1773   1.1042 0.2695      -0.1517      0.5434\n",
      "CHORES2     -0.3715         nan      nan    nan          nan         nan\n",
      "CITIZEN2     0.2239      0.0516   4.3367 0.0000       0.1227      0.3252\n",
      "DISABLE     -0.0306      0.0488  -0.6262 0.5312      -0.1263      0.0651\n",
      "DOCT_YR      0.4079      0.1008   4.0483 0.0001       0.2104      0.6054\n",
      "ER           0.2064      0.0583   3.5412 0.0004       0.0921      0.3206\n",
      "FAMILY2     -0.2431         nan      nan    nan          nan         nan\n",
      "SOCIAL2      0.5998 298711.6963   0.0000 1.0000 -585463.5667 585464.7663\n",
      "MARIT2      -0.1279      0.1658  -0.7715 0.4404      -0.4528      0.1970\n",
      "MARIT_45     0.1510      0.0130  11.6152 0.0000       0.1255      0.1765\n",
      "SERVED       0.0427      0.0241   1.7723 0.0763      -0.0045      0.0900\n",
      "SMOKING      0.3151      0.1387   2.2719 0.0231       0.0433      0.5869\n",
      "SPK_ENG      0.0257      0.0957   0.2680 0.7887      -0.1620      0.2133\n",
      "USUAL_TP    -0.1709      0.0900  -1.8982 0.0577      -0.3473      0.0056\n",
      "DSTRSYR     -0.0071      0.0084  -0.8432 0.3991      -0.0235      0.0094\n",
      "FSLEV        0.1039      0.0594   1.7508 0.0800      -0.0124      0.2203\n",
      "FSLEVCB     -0.0833      0.0751  -1.1092 0.2673      -0.2305      0.0639\n",
      "INST_12      0.0248      0.0114   2.1746 0.0297       0.0024      0.0471\n",
      "OFFTK       -0.0027      0.0104  -0.2556 0.7982      -0.0230      0.0177\n",
      "USUAL5TP     0.1443      0.1222   1.1808 0.2377      -0.0952      0.3839\n",
      "OFFTK_S     -0.0054      0.0140  -0.3880 0.6980      -0.0328      0.0220\n",
      "RBMI         0.2485      0.0315   7.8829 0.0000       0.1867      0.3103\n",
      "OVRWT       -0.0751      0.0445  -1.6901 0.0910      -0.1623      0.0120\n",
      "LATIN2TP    -0.1195      0.0361  -3.3060 0.0009      -0.1903     -0.0486\n",
      "AK10_P      -0.0000      0.0000  -1.1667 0.2433      -0.0000      0.0000\n",
      "AK10A_P     -0.0000      0.0000  -2.3250 0.0201      -0.0000     -0.0000\n",
      "AK22_P      -0.0000      0.0000  -2.6651 0.0077      -0.0000     -0.0000\n",
      "HGHTI_P     -0.0170      0.0040  -4.2931 0.0000      -0.0247     -0.0092\n",
      "WGHTP_P      0.0076      0.0008   9.7680 0.0000       0.0061      0.0092\n",
      "AJ50V2_P    -0.0533      0.0139  -3.8361 0.0001      -0.0805     -0.0261\n",
      "BMI_P       -0.0011      0.0043  -0.2583 0.7962      -0.0095      0.0073\n",
      "FAMTYP_P    -0.0085      0.0199  -0.4276 0.6689      -0.0475      0.0305\n",
      "INS64_P     -0.0406      0.0386  -1.0506 0.2934      -0.1164      0.0351\n",
      "INS64S_P     0.0253      0.0220   1.1470 0.2514      -0.0179      0.0685\n",
      "INSTYPE      0.0459      0.0259   1.7734 0.0762      -0.0048      0.0967\n",
      "PCTLF_P      0.1192      0.0242   4.9222 0.0000       0.0717      0.1667\n",
      "POVGWD_P1    0.0132      0.0059   2.2459 0.0247       0.0017      0.0247\n",
      "AC42_P      -0.0173      0.0360  -0.4812 0.6304      -0.0878      0.0532\n",
      "AD14B       -0.0213      0.0763  -0.2796 0.7798      -0.1708      0.1281\n",
      "AD17B        0.0178      0.0221   0.8018 0.4227      -0.0257      0.0612\n",
      "MAMSCRN2     0.0061      0.0691   0.0883 0.9296      -0.1293      0.1415\n",
      "ELDER_IDX    0.0221      0.0240   0.9218 0.3566      -0.0249      0.0692\n",
      "UR_CLRT      0.0282      0.0260   1.0855 0.2777      -0.0227      0.0792\n",
      "UR_CLRT2    -0.0529      0.0457  -1.1564 0.2475      -0.1424      0.0367\n",
      "AC31_P1      0.0778      0.0114   6.7997 0.0000       0.0554      0.1002\n",
      "DSTRS_P1     0.0170      0.0251   0.6767 0.4986      -0.0322      0.0662\n",
      "HHSIZE_P1    0.0267      0.0097   2.7461 0.0060       0.0077      0.0458\n",
      "AD38W       -0.0060      0.0051  -1.1737 0.2405      -0.0159      0.0040\n",
      "OMBSRR_P1    0.1031      0.0132   7.7874 0.0000       0.0772      0.1291\n",
      "SRAGE_P1     0.0217      0.0018  11.8640 0.0000       0.0181      0.0253\n",
      "RACECN_P1    0.0016      0.0141   0.1128 0.9102      -0.0261      0.0293\n",
      "RACEHP2_P1  -0.0249      0.0110  -2.2680 0.0233      -0.0464     -0.0034\n",
      "AHEDC_P1    -0.0055      0.0058  -0.9551 0.3395      -0.0168      0.0058\n",
      "RACEDF_P1   -0.1439      0.0163  -8.8433 0.0000      -0.1758     -0.1120\n",
      "WRKST_P1    -0.0497      0.0274  -1.8163 0.0693      -0.1034      0.0039\n",
      "AM38_P1     -0.0009      0.0008  -1.0318 0.3021      -0.0025      0.0008\n",
      "AK2_P1       0.0014      0.0007   2.1143 0.0345       0.0001      0.0028\n",
      "AB120B_P1   -0.1266      0.0298  -4.2471 0.0000      -0.1850     -0.0682\n",
      "AESODA_P1   -0.3352      0.0196 -17.0823 0.0000      -0.3737     -0.2968\n",
      "AG9_P1      -0.0033      0.0234  -0.1417 0.8873      -0.0491      0.0425\n",
      "AH3_P1       0.0996      0.0319   3.1259 0.0018       0.0372      0.1621\n",
      "AH52_P1     -0.0078      0.0086  -0.9052 0.3653      -0.0246      0.0091\n",
      "AH71_P1      0.0170      0.0400   0.4237 0.6718      -0.0615      0.0954\n",
      "AH72_P1      0.0083      0.0279   0.2961 0.7671      -0.0464      0.0629\n",
      "AH95_P1     -0.0196      0.0169  -1.1583 0.2467      -0.0528      0.0136\n",
      "LNGHM_P1     0.0075      0.0062   1.2015 0.2296      -0.0047      0.0196\n",
      "YRUS_P1      0.0540      0.0322   1.6774 0.0935      -0.0091      0.1170\n",
      "YEAR        -0.0007      0.0006  -1.1730 0.2408      -0.0019      0.0005\n",
      "AC42         0.0169      0.0344   0.4919 0.6228      -0.0505      0.0843\n",
      "AC46        -0.0076      0.0009  -8.8646 0.0000      -0.0093     -0.0059\n",
      "AG1          0.0255      0.0092   2.7647 0.0057       0.0074      0.0437\n",
      "AG3         -0.0965      0.0257  -3.7531 0.0002      -0.1469     -0.0461\n",
      "AH73B       -0.0447      0.0185  -2.4215 0.0155      -0.0809     -0.0085\n",
      "AJ114        0.0006      0.0312   0.0190 0.9848      -0.0605      0.0617\n",
      "AJ129        0.0597      0.0451   1.3254 0.1850      -0.0286      0.1481\n",
      "AJ136        0.2644      0.2165   1.2213 0.2220      -0.1599      0.6888\n",
      "AJ137        0.1364      0.0612   2.2298 0.0258       0.0165      0.2563\n",
      "AJ138       -0.0574         nan      nan    nan          nan         nan\n",
      "AJ139        0.0200         nan      nan    nan          nan         nan\n",
      "AJ144B      -0.0538      0.0282  -1.9074 0.0565      -0.1090      0.0015\n",
      "AK32V2       0.0635      0.0133   4.7743 0.0000       0.0374      0.0896\n",
      "AL32         0.0143      0.0153   0.9346 0.3500      -0.0157      0.0444\n",
      "AM20         0.0016      0.0090   0.1787 0.8581      -0.0159      0.0191\n",
      "INS65_S      0.0052      0.0208   0.2496 0.8029      -0.0356      0.0460\n",
      "CARE_PV     -0.3839      0.0667  -5.7528 0.0000      -0.5147     -0.2531\n",
      "DISTRESS     0.0010      0.0081   0.1287 0.8976      -0.0148      0.0169\n",
      "RN_FORGO     0.0130      0.0308   0.4228 0.6725      -0.0474      0.0735\n",
      "SC_INS       0.0200         nan      nan    nan          nan         nan\n",
      "SC_NEWP     -0.0574         nan      nan    nan          nan         nan\n",
      "TIMAPPT     -0.0248      0.0217  -1.1427 0.2532      -0.0674      0.0177\n",
      "AK7_P1       0.0001      0.0002   0.4997 0.6173      -0.0003      0.0005\n",
      "AC47         0.0004      0.0013   0.2826 0.7775      -0.0022      0.0030\n",
      "FAMSIZE2_P1 -0.0107      0.0184  -0.5849 0.5586      -0.0467      0.0252\n",
      "INDMAIN2     0.0005      0.0018   0.2668 0.7896      -0.0031      0.0041\n",
      "OCCMAIN2     0.0021      0.0015   1.3637 0.1727      -0.0009      0.0050\n",
      "COVRDCA_S   -0.0377      0.0148  -2.5400 0.0111      -0.0668     -0.0086\n",
      "ELGMAGI3     0.0376      0.0138   2.7227 0.0065       0.0105      0.0647\n",
      "AC79         0.0172      0.0177   0.9763 0.3289      -0.0174      0.0519\n",
      "AC81         0.0312      0.0175   1.7812 0.0749      -0.0031      0.0655\n",
      "AC31        -0.0222      0.0144  -1.5373 0.1242      -0.0504      0.0061\n",
      "AE95         0.0031      0.0131   0.2385 0.8115      -0.0225      0.0288\n",
      "UR_NHIS     -0.0041      0.0174  -0.2330 0.8157      -0.0383      0.0301\n",
      "INS9TP       0.0063      0.0177   0.3575 0.7207      -0.0284      0.0411\n",
      "PREDIAB     -1.3252      0.0409 -32.4073 0.0000      -1.4053     -1.2450\n",
      "AH126_P1    -0.0083      0.0072  -1.1435 0.2528      -0.0225      0.0059\n",
      "POVLL2_P1V2 -0.0085      0.0080  -1.0590 0.2896      -0.0242      0.0072\n",
      "AK3_P1V2    -0.0181      0.0075  -2.4006 0.0164      -0.0329     -0.0033\n",
      "MC_TYPE     -0.0493      0.0251  -1.9656 0.0493      -0.0984     -0.0001\n",
      "AH125_P     -0.0055      0.0061  -0.9016 0.3673      -0.0176      0.0065\n",
      "AJ167       -0.0016      0.0195  -0.0801 0.9361      -0.0398      0.0366\n",
      "AJ168        0.0498      0.0121   4.1224 0.0000       0.0261      0.0735\n",
      "FAMT4        0.0306      0.0273   1.1195 0.2629      -0.0230      0.0841\n",
      "AK22_P1     -0.0018      0.0034  -0.5306 0.5957      -0.0084      0.0048\n",
      "TIMEAD_P1V2  0.0066      0.0061   1.0684 0.2853      -0.0055      0.0186\n",
      "AC100       -0.0032      0.0082  -0.3861 0.6994      -0.0192      0.0129\n",
      "AC115        0.2424      0.0535   4.5345 0.0000       0.1376      0.3472\n",
      "AH135       -0.0024      0.0017  -1.3835 0.1665      -0.0058      0.0010\n",
      "AH5         -0.0033      0.0015  -2.2568 0.0240      -0.0062     -0.0004\n",
      "AJ172V2      0.0539      0.0263   2.0485 0.0405       0.0023      0.1055\n",
      "UR_CLRT6     0.0002      0.0207   0.0113 0.9910      -0.0403      0.0407\n",
      "UR_TRACT6   -0.0090      0.0275  -0.3291 0.7421      -0.0629      0.0448\n",
      "UR_BG6      -0.0245      0.0283  -0.8662 0.3864      -0.0800      0.0309\n",
      "AE5          0.0001      0.0019   0.0643 0.9487      -0.0035      0.0038\n",
      "AH132        0.0116         nan      nan    nan          nan         nan\n",
      "AH136       -0.0001      0.0001  -1.0542 0.2918      -0.0004      0.0001\n",
      "PINSTYPE     0.0018      0.0017   1.0470 0.2951      -0.0016      0.0052\n",
      "TCURPLAN    -0.0115         nan      nan    nan          nan         nan\n",
      "AJ175_P1     0.0091      0.0066   1.3790 0.1679      -0.0038      0.0219\n",
      "AC116_P1     0.0144      0.0089   1.6203 0.1052      -0.0030      0.0317\n",
      "AH139       -0.0413      0.0236  -1.7538 0.0795      -0.0875      0.0049\n",
      "AC144        0.0200      0.0369   0.5419 0.5879      -0.0524      0.0924\n",
      "AC161       -0.0286      0.0130  -2.2036 0.0276      -0.0541     -0.0032\n",
      "AG44        -0.0312      0.0236  -1.3256 0.1850      -0.0774      0.0149\n",
      "AM44        -0.0428      0.0171  -2.5023 0.0123      -0.0763     -0.0093\n",
      "========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check p-values of features\n",
    "import statsmodels.api as sm\n",
    "logit_model = sm.Logit(y_train, X_train)\n",
    "result = logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature with p-values less than 0.05 are the significant ones. Consider getting rid of insignificant features and then fit it into the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50339   399]\n",
      " [ 5721   278]]\n",
      "=================================================\n",
      "Kappa Score: 0.06319412019362591\n",
      "Accuracy Score: 0.8921338808890142\n",
      "Precision: 0.41063515509601184\n",
      "Recall: 0.046341056842807135\n",
      "F1 Score: 0.08328340323547034\n",
      "AUC Score: 0.5192385642131179\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================\n",
      "Average Accuracy Score: 0.8939313836015295\n",
      "Average Precision Score: 0.48220278972205616\n",
      "Average Recall Score: 0.04136891704173939\n",
      "Average F1 Score: 0.8939313836015295\n",
      "[0.89412858 0.89358472 0.89408086]\n",
      "Average AUC Score: 0.7855800695293395\n",
      "[0.77951823 0.79113178 0.7860902 ]\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "ms.metrics_summary(y_test, y_pred)\n",
    "ms.crossval_summary(logreg, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35433 15305]\n",
      " [ 1545  4454]]\n",
      "=================================================\n",
      "Kappa Score: 0.2191708488871198\n",
      "Accuracy Score: 0.7030156687875637\n",
      "Precision: 0.22541626600536466\n",
      "Recall: 0.7424570761793632\n",
      "F1 Score: 0.34583430390558273\n",
      "AUC Score: 0.7204046979698503\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================\n",
      "Average Accuracy Score: 0.6953756257138922\n",
      "Average Precision Score: 0.2200144065702135\n",
      "Average Recall Score: 0.7387836908870918\n",
      "Average F1 Score: 0.6953756257138922\n",
      "[0.68852682 0.70463867 0.69296139]\n",
      "Average AUC Score: 0.7866103484566213\n",
      "[0.77580582 0.79332475 0.79070048]\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg_cs = LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
    "logreg_cs.fit(X_train, y_train)\n",
    "y_pred = logreg_cs.predict(X_test)\n",
    "ms.metrics_summary(y_test, y_pred)\n",
    "ms.crossval_summary(logreg_cs, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using oversampled data from SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35308 15430]\n",
      " [ 1557  4442]]\n",
      "=================================================\n",
      "Kappa Score: 0.21605923048487674\n",
      "Accuracy Score: 0.7006010187355693\n",
      "Precision: 0.2235305958132045\n",
      "Recall: 0.740456742790465\n",
      "F1 Score: 0.34339608055351556\n",
      "AUC Score: 0.7181727129144095\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================\n",
      "Average Accuracy Score: 0.6972716135905482\n",
      "Average Precision Score: 0.22154594988212625\n",
      "Average Recall Score: 0.7412829914302564\n",
      "Average F1 Score: 0.6972716135905482\n",
      "[0.69956265 0.69514378 0.69710841]\n",
      "Average AUC Score: 0.788796012145836\n",
      "[0.79202477 0.78783052 0.78653274]\n",
      "=================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# implement SMOTE to oversample the minority class\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "pipeline = Pipeline(steps=[('over', SMOTE()), ('model', LogisticRegression(max_iter=1000))])\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "ms.metrics_summary(y_test, y_pred)\n",
    "ms.crossval_summary(pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use variance inflation factor to identify any significant multi-collinearity\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "X_constant = sm.add_constant(X_train, prepend=False)\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Features\"] = X_constant.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X_constant.values, i) for i in range(X_constant.shape[1])]\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set(font_scale=1.25)\n",
    "# # chis_train = pd.concat([X_train, y_train], axis=1)\n",
    "# # chis_train = chis_train.rename(columns = {'T2D': 'Type 2 Diabetes', 'AB24': 'Taking Insulin', 'AB23_P1': 'Age Told To Have Diabetes', 'AB112': 'Diabetes Care Plan', \n",
    "# # 'AB25': 'Diabetic Pills', 'AB63': 'Eye Exam Dilated Pupils', 'AB114_P1': 'Confidence to Control Diabetes', 'AB28_P1': 'Doctor Checked Feet for Sores', 'AB109': 'Visited ER', \n",
    "# # 'AB113': 'Copy of Diabetes Care Plan', 'AB111': \"Hospital Overnight for Diabetes\"})\n",
    "\n",
    "# corrMatrix = X_train.corr()\n",
    "# plt.subplots(figsize=(24, 18))\n",
    "# # g = sns.heatmap(corrMatrix, annot=True, cmap=\"Accent\", vmin=-1, vmax=1)\n",
    "# g = sns.heatmap(corrMatrix, annot=True, cmap=\"Accent\")\n",
    "# plt.title('Correlation Heatmap', size = 25)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "from statsmodels.genmod import families\n",
    "\n",
    "# Setup logistic regression model (using GLM method so that we can retrieve residuals)\n",
    "logit_model = GLM(y_train, X_constant, family=families.Binomial())\n",
    "logit_results = logit_model.fit()\n",
    "print(logit_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "# Generate residual series plot\n",
    "fig = plt.figure(figsize=(15,9))\n",
    "ax = fig.add_subplot(111, title=\"Residual Series Plot\",\n",
    "                    xlabel=\"Index Number\", ylabel=\"Deviance Residuals\")\n",
    "\n",
    "# ax.plot(X.index.tolist(), stats.zscore(logit_results.resid_pearson))\n",
    "ax.plot(X_constant.index.tolist(), scipy.stats.zscore(logit_results.resid_deviance))\n",
    "plt.axhline(y=0, ls=\"--\", color='red');"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
